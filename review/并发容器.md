# 并发容器

1. ### ConcurrentHashMap

   Hashmap多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。
   HashTable使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。
   putIfAbsent() ：没有这个值则放入map，有这个值则返回key本来对应的值。

   1. #### ConcurrentHashMap中的数据结构

      - 1.7：ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment实际继承自可重入锁（ReentrantLock），在ConcurrentHashMap里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，每个Segment里包含一个HashEntry数组，我们称之为table，每个HashEntry是一个链表结构的元素。

        ![1](https://ws3.sinaimg.cn/large/005BYqpgly1g2cp5z3zsvj30lm0fkt9e.jpg"1.7及以前")

      - 1.8:

        ![](https://ws3.sinaimg.cn/large/005BYqpgly1g2cp8e83bhj30hd09q3yh.jpg)

   2. #### ConcurrentHashMap实现原理是怎么样的或者问ConcurrentHashMap如何在保证高并发下线程安全的同时实现了性能提升？

      ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。它使用了多个锁来控制对hash表的不同部分进行的修改。内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hash table，只要多个修改操作发生在不同的段上，它们就可以并发进行。

   3. #### 初始化

      - initialCapacity：初始容量大小 ，默认16。
      - loadFactor, 扩容因子，默认0.75，当一个Segment存储的元素数量大于initialCapacity* oadFactor时，该Segment会进行一次扩容。
      - concurrencyLevel 并发度，默认16。并发度可以理解为程序运行时能够同时更新ConccurentHashMap且不产生锁竞争的最大线程数，实际上就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。如果并发度设置的过小，会带来严重的锁竞争问题；如果并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。

   4. #### 在get和put操作中，是如何快速定位元素放在哪个位置的？

      ​		对于某个元素而言，一定是放在某个segment元素的某个table元素中的

      - 定位segment：取得key的hashcode值进行一次再散列（通过Wang/Jenkins算法），拿到再散列值后，以再散列值的高位进行取模得到当前元素在哪个segment上。
      - 定位table：同样是取得key的再散列值以后，用再散列值的全部和table的长度进行取模，得到当前元素在table的哪个元素上。

   5. get（）方法

      - 定位segment和定位table后，依次扫描这个table元素下的的链表，要么找到元素，要么返回null。

      - 在高并发下的情况下如何保证取得的元素是最新的？

        用于存储键值对数据的HashEntry，在设计上它的成员变量value等都是volatile类型的，这样就保证别的线程对value值的修改，get方法可以马上看到。

        ```java
        static final class HashEntry<K,V> {
                final int hash;
                final K key;
                volatile V value;
                volatile HashEntry<K,V> next;
        }
        ```

        

   6. #### put()方法

      - 首先定位segment，当这个segment在map初始化后，还为null，由ensureSegment方法负责填充这个segment。
      - 对Segment 加锁
      - 定位所在的table元素，并扫描table下的链表

      ```java
      final V put(K key, int hash, V value, boolean onlyIfAbsent) {
          //加锁
          HashEntry<K,V> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
          V oldValue;
          try {
                      HashEntry<K,V>[] tab = table;
                      int index = (tab.length - 1) & hash;
                      HashEntry<K,V> first = entryAt(tab, index);
                      for (HashEntry<K,V> e = first;;) {
                          if (e != null) {
                              K k;
                              if ((k = e.key) == key ||
                                  (e.hash == hash && key.equals(k))) {
                                  oldValue = e.value;
                                  if (!onlyIfAbsent) {
                                      //覆盖原值
                                      e.value = value;
                                      ++modCount;
                                  }
                                  break;
                              }
                              e = e.next;
                          }
                          else {
                              //链表头节点
                              if (node != null)
                                  node.setNext(first);
                              else
                                  node = new HashEntry<K,V>(hash, key, value, first);
                              int c = count + 1;
                              if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                                  rehash(node);
                              else
                                  setEntryAt(tab, index, node);
                              ++modCount;
                              count = c;
                              oldValue = null;
                              break;
                          }
                      }
                  } finally {
                      unlock();
                  }
                  return oldValue;
              }
      ```

      

   7. #### 扩容操作

      Segment 不扩容，扩容下面的table数组，每次都是将数组翻倍

      ```java
      @SuppressWarnings("unchecked")
              private void rehash(HashEntry<K,V> node) {
                  /*
                   * Reclassify nodes in each list to new table.  Because we
                   * are using power-of-two expansion, the elements from
                   * each bin must either stay at same index, or move with a
                   * power of two offset. We eliminate unnecessary node
                   * creation by catching cases where old nodes can be
                   * reused because their next fields won't change.
                   * Statistically, at the default threshold, only about
                   * one-sixth of them need cloning when a table
                   * doubles. The nodes they replace will be garbage
                   * collectable as soon as they are no longer referenced by
                   * any reader thread that may be in the midst of
                   * concurrently traversing table. Entry accesses use plain
                   * array indexing because they are followed by volatile
                   * table write.
                   */
                  HashEntry<K,V>[] oldTable = table;
                  int oldCapacity = oldTable.length;
                  //2倍
                  int newCapacity = oldCapacity << 1;
                  threshold = (int)(newCapacity * loadFactor);
                  HashEntry<K,V>[] newTable =
                      (HashEntry<K,V>[]) new HashEntry[newCapacity];
                  int sizeMask = newCapacity - 1;
                  for (int i = 0; i < oldCapacity ; i++) {
                      HashEntry<K,V> e = oldTable[i];
                      if (e != null) {
                          HashEntry<K,V> next = e.next;
                          int idx = e.hash & sizeMask;
                          if (next == null)   //  Single node on list
                              newTable[idx] = e;
                          else { // Reuse consecutive sequence at same slot
                              HashEntry<K,V> lastRun = e;
                              int lastIdx = idx;
                              for (HashEntry<K,V> last = next;
                                   last != null;
                                   last = last.next) {
                                  int k = last.hash & sizeMask;
                                  if (k != lastIdx) {
                                      lastIdx = k;
                                      lastRun = last;
                                  }
                              }
                              newTable[lastIdx] = lastRun;
                              // Clone remaining nodes
                              for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
                                  V v = p.value;
                                  int h = p.hash;
                                  int k = h & sizeMask;
                                  HashEntry<K,V> n = newTable[k];
                                  newTable[k] = new HashEntry<K,V>(h, p.key, v, n);
                              }
                          }
                      }
                  }
                  int nodeIndex = node.hash & sizeMask; // add the new node
                  node.setNext(newTable[nodeIndex]);
                  newTable[nodeIndex] = node;
                  table = newTable;
              }
      ```

      

   8. size()方法

      size的时候进行两次不加锁的统计，两次一致直接返回结果，不一致，重新加锁再次统计

   9. 弱一致性

      get方法和containsKey方法都是通过对链表遍历判断是否存在key相同的节点以及获得该节点的value。但由于遍历过程中其他线程可能对链表结构做了调整，因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。

      

      

2. ### 常用阻塞队列

   - ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。
   - LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。
   - PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。
   - DelayQueue：一个使用优先级队列实现的无界阻塞队列。
   - SynchronousQueue：一个不存储元素的阻塞队列。
   - LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
   - ·LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。